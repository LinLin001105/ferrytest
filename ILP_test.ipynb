{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import time\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station and wharves dataframe\n",
    "wharf_df = pd.read_csv('csv_inputs/wharf_info.csv')\n",
    "\n",
    "# lines dataframe\n",
    "line_df = pd.read_csv('csv_inputs/line_info.csv')\n",
    "line_df['First_sailing'] = pd.to_datetime(line_df['First_sailing'], format='%H:%M')\n",
    "\n",
    "# Wharf to wharf transit time dataframe\n",
    "tt_df = pd.read_csv('csv_inputs/rebalancing_times.csv',index_col='From/To')\n",
    "\n",
    "# Headways dataframe\n",
    "headway_df = pd.read_csv('csv_inputs/headways.csv')\n",
    "\n",
    "# vessels\n",
    "vessel_df = pd.read_csv('csv_inputs/vessel_info.csv')\n",
    "\n",
    "# charging berths dataframe\n",
    "charging_berth = pd.read_csv('csv_inputs/charging_berths.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other input required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation time parameters\n",
    "initial_time = time(5,0)\n",
    "period_length = 5 # mins\n",
    "total_operation_hours = 10 # hours\n",
    "\n",
    "# nc, Minimum num of crew break\n",
    "nc = 0\n",
    "\n",
    "# Dc, Crew break duration (fixed)\n",
    "Dc = 10 # mins\n",
    "\n",
    "# Tc, Maximum seperation time for crew breakings\n",
    "Tc = 10*60 # mins\n",
    "\n",
    "# rv+, charging rate\n",
    "rv_plus = 2100*period_length/60/1100 # kW*h/kwh --> %  new modification (11July)\n",
    "\n",
    "# rv, discharging rate for revalancing, based on max speed of the vessel\n",
    "\n",
    "# pc. Plugging/Unplugging time\n",
    "pc = 2 # minh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set of wharves for vessels can charge, B+: ['CQ2', 'CQ4', 'CQ5', 'Bar1', 'Bar2', 'Chs1', 'Cab1', 'SOP1', 'Pm1', 'WB1', 'RB1', 'CI1', 'PB1']\n",
      "The set of wharves for vessels can do crew pause, Bc: ['cp_CQ1', 'cp_CQ2', 'cp_CQ3', 'cp_CQ4', 'cp_CQ5', 'cp_Bar1', 'cp_Bar2', 'cp_Bar4', 'cp_Bar5', 'cp_BSY1', 'cp_BSY2', 'cp_BSY3', 'cp_BSY4', 'cp_BSY5', 'cp_BSY6']\n",
      "The set of wharves for vessels can wait, B: ['CQ1', 'CQ3', 'Bar4', 'Bar5', 'BSY1', 'BSY2', 'BSY3', 'BSY4', 'BSY5', 'BSY6', 'phi_CQ2', 'phi_CQ4', 'phi_CQ5', 'phi_Bar1', 'phi_Bar2', 'phi_Chs1', 'phi_Cab1', 'phi_SOP1', 'phi_Pm1', 'phi_WB1', 'phi_RB1', 'phi_CI1', 'phi_PB1']\n"
     ]
    }
   ],
   "source": [
    "# Lset: Set of Lines\n",
    "Lset = line_df['Line_No'].unique().tolist()\n",
    "\n",
    "# Zset: Set of Sailing \n",
    "nl_ls= [len(headway_df[f'h{l}'].dropna().tolist())+1 for l in Lset]\n",
    "s_ls = [list(range(1,nl+1)) for nl in nl_ls]\n",
    "Zset = []\n",
    "\n",
    "for line in Lset:\n",
    "    for sailing in s_ls[line-1]:\n",
    "        Zset.append(f'{line}_{sailing}')\n",
    "\n",
    "# Vset: Set of Vessels\n",
    "Vset = vessel_df['Vessel code'].unique().tolist()\n",
    "\n",
    "# rv, discharging rate for revalancing, based on max speed of the vessel\n",
    "rv = {}\n",
    "for v in Vset:\n",
    "    rv_value = vessel_df[vessel_df['Vessel code'] == v]['rv'].iloc[0]\n",
    "    rv[v] = rv_value\n",
    "    \n",
    "# Wset: Set of Wharves\n",
    "Wset = wharf_df['Wharf_No'].unique().tolist()\n",
    "\n",
    "# Tset: Set of Time Periods\n",
    "Tset = [i for i in range(1, total_operation_hours * 60 // period_length + 1)]\n",
    "\n",
    "# Jset: Set of tasks\n",
    "# B+, set of wharves to charge\n",
    "Bplus = [wharf for wharf in charging_berth['Wharf_No'].unique().tolist()]\n",
    "print(f'The set of wharves for vessels can charge, B+: {Bplus}')\n",
    "\n",
    "# Non loading berths\n",
    "original_non_loading_berths = wharf_df[wharf_df['Non_loading_berths'] != 0]['Wharf_No'].unique().tolist()\n",
    "\n",
    "# Bc, set of wharves to crew pause, is copy of set B\n",
    "Bc = ['cp_' + wharf for wharf in original_non_loading_berths] # or Bc = wharf_df[wharf_df['Crew_pause'] == 'Yes']['Wharf_No'].unique().tolist()    they result in the same set\n",
    "print(f'The set of wharves for vessels can do crew pause, Bc: {Bc}')\n",
    "\n",
    "\n",
    "# B, set of wharves to wait, any wharf with a charger belongs to B, and B contains wharves with original non loading berths\n",
    "B = original_non_loading_berths.copy() \n",
    "\n",
    "for wharf in Bplus:\n",
    "    if wharf in B: # wharf with a charger\n",
    "        B.remove(wharf)\n",
    "        B.append(f'phi_{wharf}') # mark as phi(w)\n",
    "    else:\n",
    "        B.append(f'phi_{wharf}')  # input directly\n",
    "\n",
    "print(f'The set of wharves for vessels can wait, B: {B}')\n",
    "\n",
    "\n",
    "# Jset = Lset + B + B+ + Bc\n",
    "Jset = [ele for ele in Lset + B + Bc + Bplus]\n",
    "\n",
    "# Dset: Set of possible first sailing time\n",
    "# Defined later in the constraints part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tset[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cw function\n",
    "def cal_Cw(w):\n",
    "    \"\"\"\n",
    "    Calculate the total capacity (number of berths) of a specific wharf.\n",
    "\n",
    "    Parameters:\n",
    "    w (str): The wharf identifier.\n",
    "\n",
    "    Returns:\n",
    "    int: The total capacity of the wharf, including loading and non-loading berths.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the wharf identifier is not found or if required data is missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract rows corresponding to the wharf\n",
    "        wharf_data = wharf_df[wharf_df['Wharf_No'] == w]\n",
    "        \n",
    "        # Check if the wharf exists in the data\n",
    "        if wharf_data.empty:\n",
    "            raise ValueError(f\"No data found for wharf {w}. Please check the wharf identifier.\")\n",
    "        \n",
    "        # Calculate total capacity\n",
    "        loading_berths = wharf_data['Loading_berths'].iloc[0]\n",
    "        non_loading_berths = wharf_data['Non_loading_berths'].iloc[0]\n",
    "\n",
    "        # Handle possible missing values for berths\n",
    "        if pd.isna(loading_berths) or pd.isna(non_loading_berths):\n",
    "            raise ValueError(f\"Missing berth information for wharf {w}.\")\n",
    "\n",
    "        total_capacity = int(loading_berths) + int(non_loading_berths)\n",
    "        return total_capacity\n",
    "\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Missing required columns in the dataframe: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred while calculating the capacity for wharf {w}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stations visited by line 1, R_l1, is ['Circular Quay', 'Mosman']\n"
     ]
    }
   ],
   "source": [
    "# R(l) Function\n",
    "\n",
    "def cal_Rl(l):\n",
    "    \"\"\"\n",
    "    Calculate the route for a given line number from a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    l (int): The line number for which the route is to be extracted.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list containing the sequence of stations for the line, excluding any NaN entries.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the line number is not found in the DataFrame or input is not an integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check input type to be an integer\n",
    "    if not isinstance(l, int):\n",
    "        raise ValueError(\"Line number must be an integer.\")\n",
    "    \n",
    "    # Check if line number exists\n",
    "    if l not in line_df['Line_No'].values:\n",
    "        raise ValueError(f\"Line number {l} is not found in the DataFrame.\")\n",
    "    \n",
    "    try:\n",
    "        route_data = line_df[line_df['Line_No'] == l][['O', 'I', 'T']].iloc[0]\n",
    "        # Filter out NaN values and convert to list\n",
    "        R_l = [station for station in route_data if not pd.isna(station)]\n",
    "        return R_l\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"No data available for line number {l}.\")\n",
    "    except KeyError:\n",
    "        raise ValueError(\"DataFrame must include 'Line_No', 'O', 'I', 'T' columns.\")\n",
    "\n",
    "\n",
    "# Example: line1\n",
    "print(f'The stations visited by line 1, R_l1, is {cal_Rl(1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wharves in Circular Quay that can be used are: ['CQ1', 'CQ2', 'CQ3', 'CQ4', 'CQ5']\n"
     ]
    }
   ],
   "source": [
    "# C(l,S) Function\n",
    "\n",
    "def cal_C_lS(S):\n",
    "    \"\"\"\n",
    "    Calculate the set of usable wharves for a given station of a line.\n",
    "    \n",
    "    Parameters:\n",
    "    S (str): The station name for which the set of wharves is to be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of unique wharf numbers that can be used at the given station.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the station does not exist in the DataFrame or the input is not a string.\n",
    "    \"\"\"\n",
    "    # Check if input is a string\n",
    "    if not isinstance(S, str):\n",
    "        raise ValueError(\"Station name must be a string.\")\n",
    "    \n",
    "    # Check if station exists in DataFrame\n",
    "    if S not in wharf_df['Station'].values:\n",
    "        raise ValueError(f\"Station {S} is not found in the DataFrame.\")\n",
    "    \n",
    "    try:\n",
    "        # Extract unique wharves for the station\n",
    "        C_lS = wharf_df[wharf_df['Station'] == S]['Wharf_No'].unique().tolist()\n",
    "        return C_lS\n",
    "    except KeyError:\n",
    "        raise ValueError(\"DataFrame must include 'Station' and 'Wharf_No' columns.\")\n",
    "    \n",
    "\n",
    "# Example: Circular Quay\n",
    "print('The wharves in Circular Quay that can be used are:', cal_C_lS('Circular Quay'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vessel FF1 staring from Circular Quay\n"
     ]
    }
   ],
   "source": [
    "# Sv(v) Function\n",
    "\n",
    "def cal_Sv(v):\n",
    "    \"\"\"\n",
    "    Retrieve the starting station for a given vessel identified by its vessel code.\n",
    "    \n",
    "    Parameters:\n",
    "    v (str): The vessel code for which the starting station is to be retrieved.\n",
    "    \n",
    "    Returns:\n",
    "    str: The starting station of the vessel.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the vessel code does not exist in the DataFrame or the input type is incorrect.\n",
    "    \"\"\"\n",
    "    # Validate input type\n",
    "    if not isinstance(v, str):\n",
    "        raise ValueError(\"Vessel code must be a string.\")\n",
    "    \n",
    "    # Check if the vessel code exists in the DataFrame\n",
    "    if v not in vessel_df['Vessel code'].values:\n",
    "        raise ValueError(f\"Vessel code {v} is not found in the DataFrame.\")\n",
    "    \n",
    "    try:\n",
    "        # Extract the starting station for the vessel\n",
    "        S_v = vessel_df[vessel_df['Vessel code'] == v]['Sv'].iloc[0]\n",
    "        return S_v\n",
    "    except KeyError:\n",
    "        raise ValueError(\"DataFrame must include 'Vessel code' and 'Sv' columns.\")\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"No data available for vessel code {v}. The vessel might not be listed.\")\n",
    "\n",
    "# Example: Vessel FF1.\n",
    "print(f\"Vessel FF1 staring from {cal_Sv('FF1')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line served by FF1, li_ff1 : [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "def cal_li(v):\n",
    "    \"\"\"\n",
    "    Calculate the lines that a given vessel can serve, based on its starting station and the routes it can serve.\n",
    "    \n",
    "    Parameters:\n",
    "    v (str): The vessel code for which lines are to be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of line numbers that the vessel can serve starting from its designated station.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the vessel code does not exist in the DataFrame or if the DataFrame structure is incorrect.\n",
    "    \"\"\"\n",
    "    # Validate input type\n",
    "    if not isinstance(v, str):\n",
    "        raise ValueError(\"Vessel code must be a string.\")\n",
    "    \n",
    "    # Check if vessel code exists in the DataFrame\n",
    "    if v not in vessel_df['Vessel code'].values:\n",
    "        raise ValueError(f\"Vessel code {v} is not found in the DataFrame.\")\n",
    "    \n",
    "    try:\n",
    "        # Extract rows for the vessel and find routes served\n",
    "        vessel_row = vessel_df[vessel_df['Vessel code'] == v].iloc[0]\n",
    "        routes_served = [route for route in vessel_df.columns[2:-1] if vessel_row[route] == 'Yes']\n",
    "        li_v = line_df[line_df['Route_No'].isin(routes_served)]['Line_No'].tolist()\n",
    "\n",
    "        return li_v\n",
    "    except KeyError:\n",
    "        raise ValueError(\"DataFrame must include 'Vessel code', 'Route_No', 'O', and necessary route columns.\")\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"No data available for vessel code {v}.\")\n",
    "    \n",
    "# Example: Vessel FF1.\n",
    "print(f\"Line served by FF1, li_ff1 : {cal_li('FF1')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set of time for line 1's first sailing, D(l1): [19, 20, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "# D(l) Function\n",
    "\n",
    "def cal_D(l):\n",
    "    '''\n",
    "    Determines the allowable time periods for the first sailing of a specified line, \n",
    "    relative to the given initial simulation time and allowed_latitude.\n",
    "\n",
    "    Parameters:\n",
    "    l (int): Line number.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of allowable time periods, D(l), during which the specified line's\n",
    "          first sailing is considered permissible.\n",
    "\n",
    "    Example:\n",
    "    For line l1 and an initial simulation time of 5:00 AM, D(l1) might include time periods\n",
    "    where the first sailing time of line l1 falls within a certain allowable range.\n",
    "    \n",
    "    '''\n",
    "    first_sailing_time = line_df[line_df['Line_No'] == l]['First_sailing'].iloc()[0]\n",
    "    delta_minutes = (first_sailing_time.hour * 60 + first_sailing_time.minute) - (initial_time.hour * 60 + initial_time.minute)\n",
    "\n",
    "    allowed_latitude = 15 # min\n",
    "    # Create a set of allowable time period numbers\n",
    "    D_l = list(range((delta_minutes - allowed_latitude) // period_length + 1, ((delta_minutes + allowed_latitude) // period_length + 1) + 1))\n",
    "    # print(f\"The set of time for line {l}'s first sailing, D(l1): {D_l}\")\n",
    "    return D_l\n",
    "\n",
    "# Example: line 1\n",
    "print(f\"The set of time for line 1's first sailing, D(l1): {cal_D(1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h(s,d) Function\n",
    "\n",
    "def cal_h(s, d, line):\n",
    "    \"\"\"\n",
    "    Calculate the s-th sailing time starting from time 'd' for a specified 'line'.\n",
    "\n",
    "    This function retrieves headway periods for a specific line from a dataframe,\n",
    "    constructs a list of sailing times starting from time 'd', and returns the s-th\n",
    "    sailing time based on these intervals. It is used to project sailing schedules\n",
    "    based on a specified headway and start day.\n",
    "\n",
    "    Parameters:\n",
    "    s (int): The order of the sailing time to be retrieved (1st, 2nd, etc.).\n",
    "    d (int): The day from which sailing starts.\n",
    "    line (int): The line number for which headway data is to be used.\n",
    "\n",
    "    Returns:\n",
    "    int or None: The s-th sailing time in terms of the number of time periods\n",
    "                 since day 'd', or None if the index 's' is out of range or\n",
    "                 an error occurs in processing.\n",
    "\n",
    "    Note:\n",
    "    The function assumes `period_length` as a global variable that denotes the\n",
    "    length of each time period within the operational schedule.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Retrieve the headway periods for the specified line and drop missing values\n",
    "        h = headway_df[f'h{line}'].dropna().tolist()\n",
    "        h_sd_ls = [d]  # Start the list with the initial day 'd'\n",
    "\n",
    "        # Calculate subsequent sailing times based on headway periods\n",
    "        for sailing_headway in h:\n",
    "            num_time_period = int(sailing_headway // period_length + 1)  # round up\n",
    "            h_sd_ls.append(h_sd_ls[-1] + num_time_period)\n",
    "\n",
    "        # Return the s-th sailing time if within bounds\n",
    "        if s-1 < len(h_sd_ls):\n",
    "            return h_sd_ls[s-1]\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu(j) Function\n",
    "\n",
    "def cal_mu(j):\n",
    "    \"\"\"\n",
    "    Calculate the duration in time periods for a given task j.\n",
    "    \n",
    "    Parameters:\n",
    "    j (int or str): The task identifier which can be a line number, crew pause, or waiting task.\n",
    "    \n",
    "    Returns:\n",
    "    int or None: The number of time periods the task takes, or None if the task is unrecognized.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the input or required global variables are improperly configured.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(j, (int, str)):\n",
    "            raise ValueError(\"Task identifier must be an integer or string.\")\n",
    "        \n",
    "        # Check if j is in lists\n",
    "        if j in Lset:\n",
    "            mu_j = line_df[line_df['Line_No'] == j]['Line_duration'].iloc()[0] // period_length + 1\n",
    "        elif j in Bc:\n",
    "            mu_j = Dc // period_length + 1\n",
    "        elif j in Bplus or j in B:\n",
    "            mu_j = 1\n",
    "        else:\n",
    "            # If task j is unrecognized\n",
    "            return None\n",
    "        return mu_j\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Missing data for task {j}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_vjt Function\n",
    "\n",
    "def cal_q(v, j, t):\n",
    "    \"\"\"\n",
    "    Calculate the battery change rate qv,j,t for a vessel v performing task j at time t.\n",
    "\n",
    "    Parameters:\n",
    "    v (str): Identifier for the vessel.\n",
    "    j (str or int): Identifier for the task.\n",
    "    t (int): Time unit after the start of the task.\n",
    "\n",
    "    Returns:\n",
    "    float: The rate of battery change at time t.\n",
    "    \"\"\"\n",
    "\n",
    "    if j in Bplus: # the task is charging, return the charging rate\n",
    "        return rv_plus\n",
    "    elif j in B: # the task is the first or last period of charging\n",
    "        epsilon = 1-pc/period_length # REQUIRE CHECK: Do I understand this correctly ????????????????????????????????\n",
    "        return epsilon * rv_plus\n",
    "    elif j in B: # the task is waiting\n",
    "        return 0\n",
    "    elif j in Lset: # the task is a line\n",
    "        l = j\n",
    "        line_data = line_df[line_df['Line_No'] == l]\n",
    "        R_l = cal_Rl(l)\n",
    "        stops = R_l[1:] # remove the origin station\n",
    "        # Check if it's during a stop\n",
    "        if len(stops) == 1: # No intermediate stops\n",
    "            a = int(line_data['Time_underway_to_T'].iloc[0] // period_length + 1)\n",
    "            dw = int(line_data['dw_T'].iloc[0] // period_length + 1)\n",
    "            if t in list(range(a,(a+dw)+1)): # at stop\n",
    "                return 0 \n",
    "            else:\n",
    "                rj = line_data['rj'].iloc()[0]\n",
    "        elif len(stops) == 2: # with intermediate stops\n",
    "            a1 = int(line_data['Time_underway_to_I'].iloc[0] // period_length + 1)\n",
    "            dw1 = int(line_data['dw_I'].iloc[0] // period_length + 1)\n",
    "            a2 = int(line_data['Time_underway_to_T'].iloc[0] // period_length + 1)\n",
    "            dw2 = int(line_data['dw_T'].iloc[0] // period_length + 1)\n",
    "\n",
    "            if t in list(range(a1,(a1+dw1)+1)) + list(range(a2,(a2+dw2)+1)):\n",
    "                return 0\n",
    "            \n",
    "            else:\n",
    "                rj = line_data['rj'].iloc()[0]\n",
    "        return -rj  # Negative because it's a consumption rate\n",
    "    else: # the vessel is rebalncing, rv will be captured by the constraint\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New function help with the xi(j1,j2) and xi0(v,j) functions\n",
    "\n",
    "def get_task_location(j, type):\n",
    "    \"\"\"\n",
    "    Retrieve the starting station or wharf location for a given task.\n",
    "\n",
    "    Parameters:\n",
    "    j (str or int): Task identifier, which could be a line number or a specific wharf/task identifier.\n",
    "    type (int): Type of location required (0 for start or -1 for end).\n",
    "\n",
    "    Returns:\n",
    "    str: The starting station or wharf associated with the task.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the task identifier is unrecognized, necessary data is missing, or parameters are invalid.\n",
    "    IndexError: If expected data is not available in the DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type not in [0, -1]:\n",
    "            raise ValueError(\"Type parameter must be int, 0 for start or -1 for end.\")\n",
    "\n",
    "        if j in Lset:\n",
    "            task_stations = cal_Rl(j)\n",
    "            if not task_stations:\n",
    "                raise ValueError(f\"No stations found for line {j}.\")\n",
    "            task_station = task_stations[type]\n",
    "        elif j in Bc or j in B or j in Bplus:\n",
    "            task_wharf = j.split('_')[-1]\n",
    "            task_station_df = wharf_df[wharf_df['Wharf_No'] == task_wharf]\n",
    "            if task_station_df.empty:\n",
    "                raise ValueError(f\"No station found for wharf identifier {task_wharf} from task {j}.\")\n",
    "            task_station = task_station_df['Station'].iloc[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Task identifier {j} is unrecognized or does not belong to known task sets.\")\n",
    "        \n",
    "        return task_station\n",
    "    except IndexError as e:\n",
    "        raise IndexError(f\"Data retrieval error for task {j}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while retrieving the location for task {j}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xi(j1,j2) function \n",
    "# required time for j1_end and j2_start\n",
    "\n",
    "def cal_xi(j1, j2):\n",
    "    \"\"\"\n",
    "    Calculate the rebalancing time needed to travel from the end of task j1 to the start of task j2.\n",
    "\n",
    "    Parameters:\n",
    "    j1 (str or int): Task identifier for the first task.\n",
    "    j2 (str or int): Task identifier for the second task.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of time units required to transition from the end of j1 to the start of j2.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If any of the task identifiers are unrecognized, if location data is missing,\n",
    "                or if there is no travel time data available between the two tasks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the ending location of j1 and starting location of j2\n",
    "        end_location_j1 = get_task_location(j1, -1)\n",
    "        start_location_j2 = get_task_location(j2, 0)\n",
    "\n",
    "        # Check if any location data is missing\n",
    "        if not end_location_j1 in tt_df.columns or not start_location_j2 in tt_df.columns:\n",
    "            travel_time = 24*60+1 # Very long time --> ensure no rebalancing happend between the two station\n",
    "\n",
    "        # Fetch travel time from the DataFrame based on the locations\n",
    "        else:\n",
    "            travel_time = tt_df.loc[end_location_j1, start_location_j2]\n",
    "\n",
    "        # Calculate time units required for transition\n",
    "        xi_j1_j2 = travel_time // period_length + 1\n",
    "        return xi_j1_j2\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while calculating transition time from {j1} to {j2}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xi0(v,j2) function \n",
    "def cal_xi0(v, j):\n",
    "    \"\"\"\n",
    "    Calculate the time periods required for vessel v to travel from its starting position to the starting point of task j.\n",
    "    If the starting position is the same as the task location, xi0 is zero.\n",
    "    \n",
    "    Parameters:\n",
    "    v (str): The vessel identifier.\n",
    "    j (str or int): The task identifier, which could be a line or a specific wharf.\n",
    "    \n",
    "    Returns:\n",
    "    int: The time period required to travel from the vessel's starting wharf to the wharf where task j begins, or zero if they are the same.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If input data is missing or incorrect, or if travel times are not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the starting station for vessel v\n",
    "        S_v = cal_Sv(v)\n",
    "        # Fetch the starting station of the task using the refined function\n",
    "        task_station = get_task_location(j,0)\n",
    "\n",
    "        # If the starting point and task location are the same, return one\n",
    "        if S_v == task_station:\n",
    "            return 1\n",
    "        \n",
    "        elif not S_v in tt_df.columns or not task_station in tt_df.columns:\n",
    "            travel_time = 24*60+1 # Very long time --> ensure no rebalancing happend between the two station \n",
    "\n",
    "        else: # Fetch travel time from the travel time DataFrame\n",
    "            travel_time = tt_df.loc[S_v, task_station]\n",
    "\n",
    "        # Calculate periods\n",
    "        xi0 = travel_time // period_length + 1\n",
    "        return int(xi0)\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"DataFrame column missing: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_C(j):\n",
    "    \"\"\"\n",
    "    Calculate all wharves that could be used given task j.\n",
    "    If j is a line, aggregates wharves from all stations visited by the line.\n",
    "    If j is a wharf (either in B or Bc), returns just that wharf.\n",
    "\n",
    "    Parameters:\n",
    "    j (int): The task identifier, which could be a line number or a wharf.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of all wharves usable for the task, or None if task is unrecognized.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Raises an exception with a descriptive message if any error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        C_j = []\n",
    "        if isinstance(j, int) and j in Lset:\n",
    "            R_l = cal_Rl(j)  # stations visited by the line\n",
    "            for S in R_l:\n",
    "                C_lS = cal_C_lS(S)\n",
    "                C_j.extend(C_lS)  # Use extend to avoid nested lists\n",
    "        elif isinstance(j, str) and (j in Bc or B or Bplus):\n",
    "            C_j.append(j.split('_')[-1])\n",
    "        else:\n",
    "            raise ValueError(f\"Task {j} is unrecognized or inappropriate data type\")\n",
    "\n",
    "        return C_j\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta(j,w) Function\n",
    "\n",
    "def cal_delta(j, w):\n",
    "    \"\"\"\n",
    "    Calculate the set of times the wharf w will be occupied due to task j starting at time t0.\n",
    "    For lines, excludes the last station from consideration and includes a safety buffer.\n",
    "    For specific tasks like B, Bplus, or Bc, directly uses the task's duration.\n",
    "\n",
    "    Parameters:\n",
    "    j (int or str): The task identifier, which could be a line number or a specific wharf/task identifier.\n",
    "    w (str): The wharf identifier.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples (wharf, time) indicating times the wharf is occupied.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the task identifier or wharf is unrecognized, or if the wharf does not belong to the task.\n",
    "    KeyError: If necessary data columns are missing from the data frames.\n",
    "    IndexError: If data extraction based on indices fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if isinstance(j, int) and j in Lset:\n",
    "            l = j # task is a line\n",
    "            line_data = line_df[line_df['Line_No'] == l]\n",
    "            safety_buffer = 1  # Assume a safety buffer of 1 time period\n",
    "            R_l = cal_Rl(j)  # Stations visited by the line\n",
    "\n",
    "            # Exclude the first and last station # QUESTION HERE: Why do we want to remove the last station here???????????????????????????????\n",
    "            stations = R_l[1:-1]\n",
    "\n",
    "            # Iterate through intermediate stations only\n",
    "            for station in stations: # only one element here\n",
    "                wharves = cal_C_lS(station)\n",
    "                if w in wharves:\n",
    "                    a = int(line_data['Time_underway_to_I'].iloc[0] // period_length + 1)\n",
    "                    dw = int(line_data['dw_I'].iloc[0] // period_length + 1)\n",
    "                    delta_j_w = [(w, time) for time in range(a - safety_buffer, (a + dw - 1 + safety_buffer) + 1)]\n",
    "                    return delta_j_w\n",
    "\n",
    "            # raise ValueError(f\"Wharf {w} is not available for the task {j} at any intermediate stops.\")\n",
    "            return []\n",
    "\n",
    "        elif isinstance(j, str) and (j in Bc or j in B or j in Bplus):\n",
    "            if w != j.split('_')[-1]:\n",
    "                raise ValueError(f\"Task {j} should occupy its own wharf {j.split('_')[-1]}, not {w}.\")\n",
    "            mu_j = cal_mu(j)\n",
    "            delta_j_w = [(w, time) for time in range(mu_j)]\n",
    "            return delta_j_w\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Task {j} is unrecognized or has an inappropriate data type.\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Missing data column: {str(e)}\")\n",
    "    except IndexError as e:\n",
    "        raise IndexError(f\"Data extraction error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Unexpected error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F (l) Function\n",
    "\n",
    "def cal_F(l):\n",
    "    \"\"\"\n",
    "    Calculate the number of time periods from the start of a sailing until arrival at the last station of line l.\n",
    "    \n",
    "    Parameters:\n",
    "    l (int): Line\n",
    "    \n",
    "    Returns:\n",
    "    int: Time periods until arrival at the last station\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If line number does not exist or required data is missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(l, int):\n",
    "            raise ValueError(\"Line number must be an integer.\")\n",
    "        \n",
    "        time_underway_to_T = line_df[line_df['Line_No'] == l]['Time_underway_to_T'].iloc()[0]\n",
    "        F_l = time_underway_to_T // period_length + 1\n",
    "        return F_l\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"No data available for line number {l}.\")\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Missing 'Time_underway_to_T' in line_df.\")\n",
    "\n",
    "# muF(l)Function\n",
    "\n",
    "def cal_muF(l):\n",
    "    \"\"\"\n",
    "    Calculate the number of time periods a wharf is occupied at the last station by line l, including any safety buffer.\n",
    "    \n",
    "    Parameters:\n",
    "    l (int): Line number\n",
    "    \n",
    "    Returns:\n",
    "    int: Time periods a wharf is occupied\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If line number does not exist or required data is missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(l, int):\n",
    "            raise ValueError(\"Line number must be an integer.\")\n",
    "        \n",
    "        dw_T = line_df[line_df['Line_No'] == l]['dw_T'].iloc()[0]\n",
    "        muF_l = dw_T // period_length + 1\n",
    "        return muF_l\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"No data available for line number {l}.\")\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Missing 'dw_T' in line_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi(j,t) Function\n",
    "\n",
    "def cal_phi(j, t):\n",
    "    \"\"\"\n",
    "    Calculate a set of time periods within which if a task j starts, it will still be ongoing at time t.\n",
    "    \n",
    "    Parameters:\n",
    "    j (int or str): The task identifier.\n",
    "    t (int): The time period at which task j is still ongoing if started within the returned set.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of time periods representing possible start times for task j to be ongoing at time t.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the inputs are not valid or the time period is out of expected range.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if t is a valid input\n",
    "        if not isinstance(t, int) or t < 1:\n",
    "            raise ValueError(\"Time period t must be a positive integer.\")\n",
    "\n",
    "        mu_j = cal_mu(j)  # Duration that task j occupies\n",
    "        if mu_j is None:\n",
    "            raise ValueError(f\"No duration found for task {j}. It may be unrecognized.\")\n",
    "\n",
    "        # Compute the range of start times\n",
    "        phi_j_t = list(range(max(1, t - mu_j + 1), t + 1))\n",
    "        return phi_j_t\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred calculating φ(j, t): {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_j(j) Function\n",
    "\n",
    "def cal_f(j):\n",
    "    \"\"\"\n",
    "    Determines the latest feasible start time for task `j` so that it finishes before the day ends.\n",
    "\n",
    "    Parameters:\n",
    "    j (str or int): Task identifier. Can be an integer for line tasks or a string for specific wharves or tasks.\n",
    "\n",
    "    Returns:\n",
    "    int or None: The last valid starting period for the task, or None if the task cannot be completed in a day or an error occurs in processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate that Tset is properly defined and not empty\n",
    "        if not Tset:\n",
    "            raise ValueError(\"Tset is not defined or is empty.\")\n",
    "        \n",
    "        last_period = Tset[-1]  # Last time period in the set\n",
    "        \n",
    "        mu_j = cal_mu(j) # new modification 12Jul\n",
    "\n",
    "        # Calculate the latest feasible start time\n",
    "        last_start_time = last_period + 1 - mu_j\n",
    "        return last_start_time\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G(l) Function\n",
    "\n",
    "def cal_G(j):\n",
    "    \"\"\"\n",
    "    Calculate the set of valid start times for task j.\n",
    "    \n",
    "    If j is a line, G(j) includes times based on headways and initial days from D(l).\n",
    "    If j is a crew pause, waiting, or charging, G(j) includes all times in Tset.\n",
    "\n",
    "    Parameters:\n",
    "    j (int or str): The task identifier.\n",
    "\n",
    "    Returns:\n",
    "    list: List of valid start times for the task j.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If task j is unrecognized or essential data is missing.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        G_j = []\n",
    "        if j in Lset:  # a line\n",
    "            headways = headway_df.get(f'h{j}', pd.Series()).dropna().tolist()\n",
    "            if not headways:\n",
    "                raise ValueError(f\"No headway data available for line {j}\")\n",
    "            D_l = cal_D(j) \n",
    "            for d in D_l:\n",
    "                G_j.append(d)\n",
    "                current_time = d\n",
    "                for h in headways: # cal_h(s,d,l)\n",
    "                    num_time_period = int(h // period_length + 1)\n",
    "                    current_time += num_time_period\n",
    "                    G_j.append(current_time)\n",
    "        elif j in Bc or j in B or j in Bplus:  # crew pause / waiting / charging\n",
    "            G_j = Tset.copy() \n",
    "        else:\n",
    "            raise ValueError(f\"Task {j} is unrecognized or not handled.\")\n",
    "\n",
    "        return G_j\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"An error occurred processing task {j}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(v,j) Function\n",
    "\n",
    "def cal_H(v, j):\n",
    "    \"\"\"\n",
    "    Calculate the set of feasible start times H(v,j) for vessel v to start task j.\n",
    "    \n",
    "    Parameters:\n",
    "    v (int): Index of the vessel.\n",
    "    j (int or str): Index of the task, a line or a wharf.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of feasible times or None if start point is not determined.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        S_v = cal_Sv(v)\n",
    "        if pd.isna(S_v):\n",
    "            print(f'The start point of the vessel {v} has not been determined. Please determine it first.')\n",
    "            return None\n",
    "\n",
    "        xi0_vj = cal_xi0(v, j)\n",
    "        f_j = cal_f(j)\n",
    "        G_j = cal_G(j)\n",
    "\n",
    "        # Filter G(j) to find all t such that xi0(v, j) ≤ t ≤ f(j)\n",
    "        H_vj = [t for t in G_j if xi0_vj <= t <= f_j]\n",
    "\n",
    "        return H_vj\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while calculating H(v, j): {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(j,t)\n",
    "# set of tasks that can be performed-and-finished after task j\n",
    "\n",
    "def cal_taskF(j, t):\n",
    "    \"\"\"\n",
    "    Calculate the set of tasks that can be performed and finished after task j if j started at time t.\n",
    "\n",
    "    Parameters:\n",
    "    j (str or int): The task identifier for which subsequent tasks are calculated.\n",
    "    t (int): The start time of task j.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tasks that can be started and completed after task j.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the start time 't' is not valid or if 'j' does not have a feasible completion time.\n",
    "    KeyError: If there are any missing required data fields or calculations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(t, int) or t < 0:\n",
    "            raise ValueError(\"Start time 't' must be a non-negative integer.\")\n",
    "        \n",
    "        feasible_tasks = []\n",
    "        f_j = cal_f(j)  # Calculate the latest feasible start time for task j\n",
    "\n",
    "        if t > f_j:\n",
    "            return feasible_tasks  # Return an empty list if j can't be completed\n",
    "\n",
    "        mu_j = cal_mu(j)  # Duration of task j\n",
    "\n",
    "        # Loop through all tasks in the global set Jset to find feasible subsequent tasks\n",
    "        for j_prime in Jset:\n",
    "            f_j_prime = cal_f(j_prime)  # Latest feasible start time for task j'\n",
    "            xi_j_j_prime = cal_xi(j, j_prime)  # Travel time from task j to task j'\n",
    "\n",
    "            # Check if task j' can start after j considering travel time and its own constraints\n",
    "            if f_j_prime >= t + mu_j + xi_j_j_prime:\n",
    "                feasible_tasks.append(j_prime)\n",
    "\n",
    "        return feasible_tasks\n",
    "\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Missing data for task calculation: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E(w,t) Function\n",
    "\n",
    "def cal_E(w, t):\n",
    "    \"\"\"\n",
    "    Calculate the set of pairs (j, t') such that starting task j at time t' results in using a wharf\n",
    "    at station associated with wharf w at time t.\n",
    "\n",
    "    Parameters:\n",
    "    w (str): Wharf identifier.\n",
    "    t (int): Specific time point.\n",
    "\n",
    "    Returns:\n",
    "    set: Set of pairs (j, t') meeting the specified conditions.\n",
    "    \"\"\"\n",
    "    E_wt = []\n",
    "\n",
    "    for j in Jset:\n",
    "        C_j = cal_C(j)  # Set of wharves usable for task j\n",
    "        # print(f'target wharf: {w}, current task {j}, wharf available for task:{C_j}') \n",
    "        if w in C_j:\n",
    "            delta_jw = cal_delta(j, w)  # Set of time units allowed between t' and t for task j and wharf w\n",
    "            # for t_prime in [time for time in Tset if time <= t]:\n",
    "            for t_prime in range(0,t+1):\n",
    "                if (t - t_prime) in [usage[1] for usage in delta_jw]: # delta_jw output (w, time)\n",
    "                    E_wt.append((j, t_prime)) # store the task and it's start time\n",
    "\n",
    "        return E_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-06-26\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = gp.Model(\"Ferry test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dset: Set of Departures Times\n",
    "D_l = [cal_D(l) for l in Lset]\n",
    "Dset = {l: d for l, d in zip(Lset, D_l)}\n",
    "\n",
    "# variable x[l, d]\n",
    "x = {}\n",
    "for l in Lset:\n",
    "    for d in Dset[l]:\n",
    "        x[l, d] = model.addVar(vtype=GRB.BINARY, name=f\"x_{l}_{d}\")\n",
    "\n",
    "# variable y[v, j, t]\n",
    "y = {}\n",
    "for v in Vset:\n",
    "    for j in Jset:\n",
    "        for t in Tset:\n",
    "            y[v, j, t] = model.addVar(vtype=GRB.BINARY, name=f\"y_{v}_{j}_{t}\")\n",
    "\n",
    "# variable Q[v, t]\n",
    "Q = {}\n",
    "for v in Vset: \n",
    "    for t in Tset:\n",
    "        Q[v, t] = model.addVar(vtype=GRB.CONTINUOUS, lb=0.0, ub=1.0, name=f\"Q_{v}_{t}\")\n",
    "\n",
    "\n",
    "# variable z[j, w]\n",
    "z = {}\n",
    "for j in Jset:\n",
    "    C_j = cal_C(j)\n",
    "    for w in C_j: \n",
    "        z[w,j] = model.addVar(vtype=GRB.BINARY, name=f\"z_{w}_{j}\")\n",
    "\n",
    "\n",
    "# variable Z[l, w, t]\n",
    "Z = {}\n",
    "for l in Lset:\n",
    "    A_l = cal_Rl(l)[-1]\n",
    "    C_lS = cal_C_lS(A_l)\n",
    "    for w in C_lS:\n",
    "        for t in Tset:\n",
    "            Z[l, w, t] = model.addVar(vtype=GRB.BINARY, name=f\"Z_{l}_{w}_{t}\")\n",
    "\n",
    "# variable Z'[l, w, t]\n",
    "Z_prime = {}\n",
    "for l in Lset:\n",
    "    A_l = cal_Rl(l)[-1]\n",
    "    C_lS = cal_C_lS(A_l)\n",
    "    for w in C_lS:\n",
    "        for t in Tset:\n",
    "            Z_prime[l, w, t] = model.addVar(vtype=GRB.BINARY, name=f\"Z_prime_{l}_{w}_{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cal_taskF(j, t), taskF_results\n",
    "# taskF_results = {}\n",
    "# for j in tqdm(Jset, desc='taskF_results'):\n",
    "#     for t in Tset:\n",
    "#         taskF_results[(j, t)] = cal_taskF(j, t)\n",
    "\n",
    "# # cal_mu(j), mu_results\n",
    "# mu_results = {}\n",
    "# for j in tqdm(Jset, desc='mu_results'):\n",
    "#     mu_results[j] = cal_mu(j)\n",
    "\n",
    "# # cal_xi(j, j_prime), xi_results\n",
    "# xi_results = {}\n",
    "# for j in tqdm(Jset, desc='xi_results'):\n",
    "#     for j_prime in Jset:\n",
    "#         xi_results[(j, j_prime)] = cal_xi(j, j_prime)\n",
    "\n",
    "# # cal_phi(j, t) phi_results\n",
    "# phi_results = {}\n",
    "# for j in tqdm(Jset, desc='phi_results'):\n",
    "#     for t in Tset:\n",
    "#         phi_results[(j, t)] = cal_phi(j, t)\n",
    "\n",
    "# # cal_E(w, t), E_results\n",
    "# E_results = {}\n",
    "# for w in tqdm(Wset, desc='E_results'):\n",
    "#     for t in Tset:\n",
    "#         # print(w,t)\n",
    "#         E_results[(w, t)] = cal_E(w, t)\n",
    "\n",
    "# # Save\n",
    "# with open('pkl_files/taskF_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(taskF_results, f)\n",
    "# with open('pkl_files/mu_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(mu_results, f)\n",
    "# with open('pkl_files/xi_jj_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(xi_results, f)\n",
    "# with open('pkl_files/phi_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(phi_results, f)\n",
    "# with open('pkl_files/E_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(E_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results matrixes ready!\n"
     ]
    }
   ],
   "source": [
    "# read \n",
    "with open('pkl_files/taskF_results.pkl', 'rb') as f:\n",
    "    taskF_results = pickle.load(f)\n",
    "with open('pkl_files/mu_results.pkl', 'rb') as f:\n",
    "    mu_results = pickle.load(f)\n",
    "with open('pkl_files/xi_jj_results.pkl', 'rb') as f:# read\n",
    "    xi_results = pickle.load(f)\n",
    "with open('pkl_files/E_results.pkl', 'rb') as f:\n",
    "    E_results = pickle.load(f)\n",
    "with open('pkl_files/phi_results.pkl', 'rb') as f: # read\n",
    "    phi_results = pickle.load(f)\n",
    "\n",
    "print('All results matrixes ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1a\n",
    "for l in Lset:\n",
    "    model.addConstr(gp.quicksum(x[l, d] for d in Dset[l]) == 1, name=f\"departure_time_constraint_{l}_d{d}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1b\n",
    "for sailing in Zset:  \n",
    "    l = int(sailing.split('_')[0]) # line\n",
    "    s = int(sailing.split('_')[1]) # nth sailing\n",
    "    # print(f'line:{l},sailing:{s}')\n",
    "    for d in Dset[l]:\n",
    "        h_sd = cal_h(s,d,l)\n",
    "        t = h_sd\n",
    "        model.addConstr(gp.quicksum(y[v, l, t] for v in Vset) == x[l, d],name=f\"assign_vessel_s{s}_d{d}_l{l}\")#12JUl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1c\n",
    "for v in Vset:\n",
    "    for j in Jset:\n",
    "        H_vj = cal_H(v,j)\n",
    "        for t in [t for t in Tset if t not in H_vj]:\n",
    "            y[v, j, t].ub = 0  # Set upper bound of y[v,j,t] to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1d\n",
    "for t in Tset:\n",
    "    for v in Vset:\n",
    "        li_v = cal_li(v)\n",
    "        for j in [l for l in Lset if l not in li_v]:\n",
    "            y[v, j, t].ub = 0  # Set upper bound of y[v,j,t] to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1e\n",
    "for v in Vset:   \n",
    "    for j in Jset:\n",
    "        xi0_v_j = cal_xi0(v,j)\n",
    "        t = xi0_v_j\n",
    "        if t in Tset:\n",
    "            model.addConstr(gp.quicksum(y[v, j, t] for j in Jset) == 1,name=f\"assign_task_v{v}_j{j}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1f\n",
    "for v in Vset:\n",
    "    for t in Tset:\n",
    "        model.addConstr(gp.quicksum(y[v, j, t_prime] for j in Jset for t_prime in phi_results[(j, t)]) <= 1,name=f\"task_overlap_v{v}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1g\n",
    "for l in Lset:\n",
    "    R_l = cal_Rl(l)\n",
    "    A_l = R_l[-1] # last station\n",
    "    for S in [station for station in R_l if station != A_l]:\n",
    "        C_lS = cal_C_lS(S)\n",
    "        model.addConstr(gp.quicksum(z[w, l] for w in C_lS) == 1,name=f\"select_one_wharf_{l}_station_{S}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1h\n",
    "for l in Lset:\n",
    "    F_l = cal_F(l)\n",
    "    for t in Tset:\n",
    "        if t > F_l:\n",
    "            A_l = cal_Rl(l)[-1] # last station\n",
    "            C_lS = cal_C_lS(A_l) # available wharves at last station\n",
    "            model.addConstr(gp.quicksum(Z[l, w, t] for w in C_lS) == gp.quicksum(y[v, l, t - F_l] for v in Vset),name=f\"last_wharf_use_{l}_w{w}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1i\n",
    "for l in Lset:\n",
    "    A_l = cal_Rl(l)[-1]\n",
    "    C_lS = cal_C_lS(A_l)\n",
    "    for w in C_lS:\n",
    "        muF_l = cal_muF(l)\n",
    "        for t in Tset:\n",
    "            if t > muF_l-1:\n",
    "                model.addConstr(Z_prime[l, w, t] == gp.quicksum(Z[l, w, t - k] for k in range(muF_l)), name=f\"wharf_occupation_{l}_{w}_t{t}\")         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1j\n",
    "for v in Vset:\n",
    "    for w in Bplus:\n",
    "        for t in Tset: \n",
    "            if t > 1:\n",
    "                phi_w = f'phi_{w}'\n",
    "                # j = w\n",
    "                model.addConstr(y[v, w, t] <= y[v, w, t - 1] + y[v, phi_w, t - 1], name=f\"full_period_charging_1_v{v}_w{w}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 1k\n",
    "for v in Vset:\n",
    "    for w in Bplus:\n",
    "        for t in Tset: \n",
    "            if t <= Tset[-1]-1:\n",
    "                phi_w = f'phi_{w}'\n",
    "                # j = w\n",
    "                model.addConstr(y[v, w, t] <= y[v, w, t + 1] + y[v, phi_w, t + 1], name=f\"full_period_charging_2_v{v}_w{w}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint 2: 100%|██████████| 27/27 [00:06<00:00,  4.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Constraint 2 \n",
    "for v in tqdm(Vset, desc='Constraint 2'):\n",
    "    for j in Jset:\n",
    "        for t in Tset:\n",
    "            follow_tasks = taskF_results[(j, t)]\n",
    "            if follow_tasks != []:\n",
    "                model.addConstr(gp.quicksum(y[v, j_prime, t + mu_results[j] + xi_results[(j, j_prime)]] for j_prime in follow_tasks) >= y[v, j, t], name=f\"follow_task_v{v}_j{j}_t{t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint 3: 100%|██████████| 27/27 [03:26<00:00,  7.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# Constraint 3\n",
    "for v in tqdm(Vset, desc='Constraint 3'):\n",
    "    for j in Jset:\n",
    "        for t in Tset:\n",
    "            for j_prime in taskF_results[(j, t)]:\n",
    "                for t_prime in range(t + mu_results[j], t + mu_results[j] + xi_results[(j, j_prime)]):\n",
    "                    if t_prime in Tset:# mew modification\n",
    "                        model.addConstr(y[v, j, t] + y[v, j_prime, t_prime] <= 1, name=f\"no_overlap_v{v}_j{j}_t{t}_j_prime{j_prime}_t_prime{t_prime}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 4\n",
    "for w in Wset:\n",
    "    for t in Tset:\n",
    "        # Sum over y and z\n",
    "        sum_yz = gp.quicksum(y[v, j, t_prime] * z[w, j] for v in Vset for (j, t_prime) in E_results[(w, t)])\n",
    "        # Sum over Z_prime with key check\n",
    "        sum_Z_prime = gp.quicksum(Z_prime[l, w, t] for l in Lset if (l, w, t) in Z_prime) \n",
    "        \n",
    "        model.addConstr(sum_yz + sum_Z_prime <= cal_Cw(w), name=f\"capacity_constraint_w{w}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 5a, 5b\n",
    "for v in Vset:\n",
    "    for t in Tset:\n",
    "        model.addConstr(Q[v, t] >= 0, name=f\"battery_non_negative_v{v}_t{t}\") \n",
    "\n",
    "for v in Vset:\n",
    "    for t in Tset:\n",
    "        model.addConstr(Q[v, t] <= 1, name=f\"battery_max_capacity_v{v}_t{t}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constraint 5c: 100%|██████████| 27/27 [03:13<00:00,  7.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Constraint 5c\n",
    "rv = {}\n",
    "for v in Vset:\n",
    "    rv_value = vessel_df[vessel_df['Vessel code'] == v]['rv'].iloc[0]\n",
    "    rv[v] = rv_value\n",
    "\n",
    "Qv0 = {}\n",
    "for v in Vset:\n",
    "    rv0_value = vessel_df[vessel_df['Vessel code'] == v]['Qv0'].iloc()[0]\n",
    "    Qv0[v] = rv0_value\n",
    "\n",
    "for v in tqdm(Vset, desc='Constraint 5c'):\n",
    "    for t in Tset:\n",
    "        if t == 1:\n",
    "            model.addConstr(Qv0[v] \n",
    "                        + gp.quicksum(cal_q(v, j, t - t_prime) * y[v, j, t_prime] for j in Jset for t_prime in phi_results[(j, t)]) \n",
    "                        - rv[v] * (1 - gp.quicksum(y[v, j, t_prime] for j in Jset for t_prime in phi_results[(j, t)])) \n",
    "                        >= Q[v, t], \n",
    "                        name=f\"battery_update_v{v}_t{t}\")     \n",
    "        else:\n",
    "            model.addConstr(Q[v, t - 1] \n",
    "                            + gp.quicksum(cal_q(v, j, t - t_prime) * y[v, j, t_prime] for j in Jset for t_prime in phi_results[(j, t)]) \n",
    "                            - rv[v] * (1 - gp.quicksum(y[v, j, t_prime] for j in Jset for t_prime in phi_results[(j, t)])) \n",
    "                            >= Q[v, t], \n",
    "                            name=f\"battery_update_v{v}_t{t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 Jul\n",
    "# Constraint 6a\n",
    "for v in Vset:\n",
    "    model.addConstr(gp.quicksum(y[v, j, t] for j in Bc for t in Tset) >= nc, name=f\"min_crew_pauses_v{v}_j{j}_{t}\")\n",
    "\n",
    "# Constraint 6b\n",
    "for v in Vset:\n",
    "    for t in Tset:\n",
    "        if t < (Tset[-1] - (Tc // period_length + 1)):\n",
    "            for t_prime in range(1, Tc // period_length + 1):\n",
    "                model.addConstr(gp.quicksum(y[v, j, t + t_prime] for j in Bc) >= 1, name=f\"max_distance_pauses_v{v}_t{t}_t{t}_t_prime{t_prime}\") #12JUl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable psi[v]\n",
    "psi = {}\n",
    "for v in Vset:\n",
    "    psi[v] = model.addVar(vtype=GRB.BINARY, name=f\"psi_{v}\")\n",
    "\n",
    "# Objective Function 7\n",
    "model.setObjective(gp.quicksum(psi[v] for v in Vset), GRB.MINIMIZE)\n",
    "\n",
    "# Objective Function 8\n",
    "M = Tset[-1]\n",
    "\n",
    "for v in Vset:\n",
    "    model.addConstr(psi[v] >= (1 / M) * gp.quicksum(y[v, l, t] for l in Lset for t in Tset), name=f\"utilize_vessel_{v}\")\n",
    "\n",
    "# Objective Function 9: Minimizing Rebalancing Time\n",
    "\n",
    "# This constraint requires a very long time to run. So, I manually killed the terminal here.\n",
    "\n",
    "rebalancing_time = gp.quicksum(\n",
    "    1 - gp.quicksum(y[v, j, t_prime] for j in Jset for t_prime in cal_phi(j, t))\n",
    "    for v in Vset for t in Tset\n",
    ")\n",
    "model.setObjective(rebalancing_time, GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "# # This one is equivalant to the function 9\n",
    "# # Objective Function 10: Maximizing Time Not Being Rebalanced\n",
    "# not_rebalancing_time = gp.quicksum(\n",
    "#     gp.quicksum(y[v, j, t_prime] for j in Jset for t_prime in cal_phi(j, t))\n",
    "#     for v in Vset for t in Tset\n",
    "# )\n",
    "# model.setObjective(not_rebalancing_time, GRB.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with 0 variables and 0 constraints.\n",
      "\n",
      "Set parameter InfUnbdInfo to value 1\n",
      "Set parameter Presolve to value 2\n",
      "Set parameter ScaleFlag to value 1\n",
      "Gurobi Optimizer version 11.0.2 build v11.0.2rc0 (mac64[arm] - Darwin 23.5.0 23F79)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 47995047 rows, 244303 columns and 110967164 nonzeros\n",
      "Model fingerprint: 0x7bd94d96\n",
      "Variable types: 3240 continuous, 241063 integer (241063 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-07, 1e+00]\n",
      "  Objective range  [1e+00, 2e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [4e-02, 2e+00]\n",
      "Presolve removed 3840 rows and 0 columns (presolve time = 5s) ...\n",
      "Presolve removed 3840 rows and 55697 columns (presolve time = 10s) ...\n",
      "Presolve removed 15496409 rows and 57062 columns (presolve time = 19s) ...\n",
      "Presolve removed 15496409 rows and 63599 columns (presolve time = 20s) ...\n",
      "Presolve removed 15496409 rows and 63599 columns\n",
      "Presolve time: 20.29s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 29.14 seconds (33.09 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n",
      "Optimization completed with status: 3\n",
      "Model is infeasible; computing IIS...\n",
      "Gurobi Optimizer version 11.0.2 build v11.0.2rc0 (mac64[arm] - Darwin 23.5.0 23F79)\n",
      "\n",
      "CPU model: Apple M2\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "\n",
      "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
      "\n",
      "           Constraints          |            Bounds           |  Runtime\n",
      "      Min       Max     Guess   |   Min       Max     Guess   |\n",
      "--------------------------------------------------------------------------\n",
      "        0  32506587         -         0     61833         -           1s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting optimization with {model.NumVars} variables and {model.NumConstrs} constraints.\\n\")\n",
    "\n",
    "# Modify parameters for detailed output and diagnostics\n",
    "model.setParam('OutputFlag', 1)\n",
    "model.setParam('InfUnbdInfo', 1)\n",
    "model.setParam('Presolve', 2)\n",
    "model.setParam('ScaleFlag', 1)\n",
    "model.setParam('FeasibilityTol', 1e-6)\n",
    "# model.setParam('NodeLimit', 100000)  # limit the number of nodes\n",
    "# model.setParam('MIPFocus', 1)  # focus on finding feasible solutions\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "print(f\"Optimization completed with status: {model.Status}\")\n",
    "\n",
    "if model.status == GRB.INFEASIBLE:\n",
    "    print(\"Model is infeasible; computing IIS...\")\n",
    "    model.computeIIS()\n",
    "    print(\"The following constraints and/or bounds are contributing to the infeasibility:\")\n",
    "    for c in model.getConstrs():\n",
    "        if c.IISConstr:\n",
    "            print(f\"{c.constrName} is in the IIS.\")\n",
    "    for v in model.getVars():\n",
    "        if v.IISLB > 0 or v.IISUB > 0:\n",
    "            print(f\"{v.VarName} is in the IIS.\")\n",
    "    model.write(\"test.ilp\")\n",
    "\n",
    "def save_variable_results(var_dict, filename):\n",
    "    results = {k: (var_dict[k].X if var_dict[k].Xn <= var_dict[k].UB and var_dict[k].Xn >= var_dict[k].LB else \"Out of bounds\") for k in var_dict.keys()}\n",
    "    df = pd.DataFrame(list(results.items()), columns=['Variable', 'Value'])\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Results saved to {filename} with {len(results)} entries.\")\n",
    "\n",
    "\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimization was successful. Saving results...\")\n",
    "    \n",
    "    # Save results\n",
    "    save_variable_results(x, 'x_variable_results.csv')\n",
    "    save_variable_results(y, 'y_variable_results.csv')\n",
    "    save_variable_results(Q, 'Q_variable_results.csv')\n",
    "    save_variable_results(z, 'z_variable_results.csv')\n",
    "    save_variable_results(Z, 'Z_variable_results.csv')\n",
    "    save_variable_results(Z_prime, 'Z_prime_variable_results.csv')\n",
    "else:\n",
    "    print(\"Optimization did not reach optimality.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
